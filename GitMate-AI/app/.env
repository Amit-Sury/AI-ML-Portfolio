#Github configs
GITHUB_APP_ID=Id of your app
GITHUB_APP_PRIVATE_KEY=./config/sample_privatekey.pem
GITHUB_REPOSITORY=Userid/Reponame
OPENAI_API_KEY=privatekey

#Set LLM type:
LLM_TYPE=1
    # 1: Ollama 
    # 2: AWS Bedrock Claude Haiku
    # 3: GPT

#Set Model ID
LLM_MODEL_ID=hf.co/bartowski/Llama-3.2-3B-Instruct-GGUF:Q4_K_M
    # Ollama_Llama-3.2-1B: hf.co/bartowski/Llama-3.2-1B-Instruct-GGUF 
    # Ollama_Llama-3.2-3B: hf.co/bartowski/Llama-3.2-3B-Instruct-GGUF:Q4_K_M
    # AWS Bedrock Claude: anthropic.claude-3-haiku-20240307-v1:0
    # GPT: gpt-5-nano

#Ollama base URL
BASE_URL=http://localhost:11434
    #For direct script use: http://localhost:11434
    #For docker use: http://host.docker.internal:11434

#Logging
HISTORY_PATH=./history/
LOG_PATH=./logs/
# enable debug log? 0: disabled, 1: enabled
DEBUG_LOG=1 
# enable logging langchain messages? 0: disabled, 1: enabled
WRITE_LANGCHAIN_MSGS=1 


#langsmith env variables
LANGCHAIN_TRACING_V2=false
LANGCHAIN_API_KEY=privatekey
LANGCHAIN_PROJECT=my-sample-project
LANGCHAIN_ENDPOINT=https://api.smith.langchain.com





